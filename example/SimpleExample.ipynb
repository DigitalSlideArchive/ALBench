{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf11c9d-a1e2-4e9f-9c04-62746cc69738",
   "metadata": {},
   "source": [
    "<h1>al_bench</h1>\n",
    "Example use of the al_bench Active Learning Benchmark Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd2592-b935-4131-9c2e-aa08c4c25ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install needed packages\n",
    "!pip install h5py numpy tensorflow\n",
    "!pip install -e /tf/notebooks/al_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7e1bd-8315-413d-b3ee-2d38e0777819",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>\n",
    "Fetch a dataset of 4598 feature vectors of length 1280 and their 4598 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5440303-b2c7-49b8-9524-f2159c8e825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 4598 feature vectors of length 1280.\n",
      "Read in 4598 labels for the feature vectors.\n"
     ]
    }
   ],
   "source": [
    "import al_bench as alb\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "filename = \"../test/TCGA-A2-A0D0-DX1_xmin68482_ymin39071_MPP-0.2500.h5py\"\n",
    "with h5.File(filename) as ds:\n",
    "    my_features = np.array(ds[\"features\"])\n",
    "    print(\n",
    "        f\"Read in {my_features.shape[0]} feature vectors of length {my_features.shape[1]}.\"\n",
    "    )\n",
    "    my_labels = np.array(ds[\"labels\"])\n",
    "    print(f\"Read in {my_labels.shape[0]} labels for the feature vectors.\")\n",
    "my_label_definitions = [\n",
    "    {\n",
    "        0: {\"description\": \"other\"},\n",
    "        1: {\"description\": \"tumor\"},\n",
    "        2: {\"description\": \"stroma\"},\n",
    "        3: {\"description\": \"infiltrate\"},\n",
    "    }\n",
    "]\n",
    "my_dataset_handler = alb.dataset.GenericDatasetHandler()\n",
    "my_dataset_handler.set_all_features(my_features)\n",
    "my_dataset_handler.set_all_label_definitions(my_label_definitions)\n",
    "my_dataset_handler.set_all_labels(my_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665ae47-e23f-461c-9167-4e4443c4fb81",
   "metadata": {},
   "source": [
    "<h2>Model</h2>\n",
    "Build a model that we will train.  We choose a TensorFlow model, but we could have chosen a PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4213fa-9f3f-4340-b5af-1ae3eb0b0e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 09:42:27.302380: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-09 09:42:29.578625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1922] Ignoring visible gpu device (device: 1, name: Quadro P400, pci bus id: 0000:a6:00.0, compute capability: 6.1) with core count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-09-09 09:42:29.579257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-09 09:42:30.456674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22344 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "number_of_categories = len(my_label_definitions[0])\n",
    "number_of_features = my_features.shape[1]\n",
    "hidden_units = 128\n",
    "dropout = 0.3\n",
    "my_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(number_of_features,)),\n",
    "        tf.keras.layers.Dense(hidden_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout, noise_shape=None, seed=20220909),\n",
    "        tf.keras.layers.Dense(number_of_categories, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=(\n",
    "        f\"{number_of_categories}_labels_from_{number_of_features}_features_with_\"\n",
    "        f\"dropout_{dropout}\"\n",
    "    ),\n",
    ")\n",
    "my_model_handler = alb.model.TensorFlowModelHandler()\n",
    "my_model_handler.set_model(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e961066-33aa-4ce6-b13d-91927aa6102e",
   "metadata": {},
   "source": [
    "<h2>Active Learning Strategy</h2>\n",
    "Choose an active learning strategy to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7331ecb0-90b8-4b51-b5f1-4c1e1bd855c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_strategy_handler = alb.strategy.RandomStrategyHandler()\n",
    "my_strategy_handler = alb.strategy.LeastConfidenceStrategyHandler()\n",
    "# my_strategy_handler = alb.strategy.LeastMarginStrategyHandler()\n",
    "# my_strategy_handler = alb.strategy.EntropyStrategyHandler()\n",
    "\n",
    "my_strategy_handler.set_dataset_handler(my_dataset_handler)\n",
    "my_strategy_handler.set_model_handler(my_model_handler)\n",
    "my_strategy_handler.set_learning_parameters(\n",
    "    label_of_interest=0,  # We've supplied only one label per feature vector\n",
    "    maximum_iterations=5,\n",
    "    number_to_select_per_iteration=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c97f48-383f-41e9-af12-3a317e9b7c87",
   "metadata": {},
   "source": [
    "<h2>Run the benchmarking tool</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f064a10-ed81-4cbc-b7aa-85b9ce56c52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for 4598 examples\n",
      "108/144 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 09:42:33.114182: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 1ms/step\n",
      "Training with 20 examples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 1.4931 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8506 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1993 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1808 - accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 1.0000\n",
      "Predicting for 4598 examples\n",
      "144/144 [==============================] - 0s 2ms/step\n",
      "Training with 40 examples\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8919 - accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5910 - accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0888 - accuracy: 1.0000\n",
      "Predicting for 4598 examples\n",
      "144/144 [==============================] - 0s 1ms/step\n",
      "Training with 60 examples\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 0.4626 - accuracy: 0.7333\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2790 - accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1626 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.9833\n",
      "Predicting for 4598 examples\n",
      "144/144 [==============================] - 0s 1ms/step\n",
      "Training with 80 examples\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8375\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1773 - accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9375\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9875\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 1.0000\n",
      "Predicting for 4598 examples\n",
      "144/144 [==============================] - 0s 1ms/step\n",
      "Training with 100 examples\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8800\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9300\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9600\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9700\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "Predicting for 4598 examples\n",
      "144/144 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assume that we start with nothing labeled\n",
    "currently_labeled_examples = set()\n",
    "my_strategy_handler.run(currently_labeled_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_bench",
   "language": "python",
   "name": "al_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
