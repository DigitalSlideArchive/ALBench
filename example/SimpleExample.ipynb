{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf11c9d-a1e2-4e9f-9c04-62746cc69738",
   "metadata": {},
   "source": [
    "<h1>al_bench</h1>\n",
    "Example use of the al_bench Active Learning Benchmark Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97782e2-22b6-492d-aadb-ea622f37ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install needed packages\n",
    "!pip install h5py numpy tensorflow\n",
    "!pip install -e /tf/notebooks/al_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7e1bd-8315-413d-b3ee-2d38e0777819",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>\n",
    "Fetch a dataset of 4598 feature vectors of length 1280 and their 4598 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5440303-b2c7-49b8-9524-f2159c8e825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 08:32:15.386396: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 4598 feature vectors of length 1280.\n",
      "Read in 4598 labels for the feature vectors.\n"
     ]
    }
   ],
   "source": [
    "import al_bench as alb\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "filename = \"../test/TCGA-A2-A0D0-DX1_xmin68482_ymin39071_MPP-0.2500.h5py\"\n",
    "with h5.File(filename) as ds:\n",
    "    my_features = np.array(ds[\"features\"])\n",
    "    print(\n",
    "        f\"Read in {my_features.shape[0]} feature vectors of length {my_features.shape[1]}.\"\n",
    "    )\n",
    "    my_labels = np.array(ds[\"labels\"])\n",
    "    print(f\"Read in {my_labels.shape[0]} labels for the feature vectors.\")\n",
    "my_label_definitions = [\n",
    "    {\n",
    "        0: {\"description\": \"other\"},\n",
    "        1: {\"description\": \"tumor\"},\n",
    "        2: {\"description\": \"stroma\"},\n",
    "        3: {\"description\": \"infiltrate\"},\n",
    "    }\n",
    "]\n",
    "my_dataset_handler = alb.dataset.GenericDatasetHandler()\n",
    "my_dataset_handler.set_all_features(my_features)\n",
    "my_dataset_handler.set_all_label_definitions(my_label_definitions)\n",
    "my_dataset_handler.set_all_labels(my_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665ae47-e23f-461c-9167-4e4443c4fb81",
   "metadata": {},
   "source": [
    "<h2>Model</h2>\n",
    "Build a model that we will train.  We will build both a TensorFlow model and a PyTorch model, though normally one model is sufficient.  We'll choose one of them for use with the active learning strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3576b1b9-a56a-44c0-ab72-3a4011d927ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "number_of_categories = len(my_label_definitions[0])\n",
    "number_of_features = my_features.shape[1]\n",
    "hidden_units = 128\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7350441-53c9-4d31-b5ac-178f984b2698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow model handler built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 08:32:17.022095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1922] Ignoring visible gpu device (device: 1, name: Quadro P400, pci bus id: 0000:a6:00.0, compute capability: 6.1) with core count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-09-26 08:32:17.022632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-26 08:32:17.604462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22344 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "my_tensorflow_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(number_of_features,)),\n",
    "        tf.keras.layers.Dense(hidden_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout, noise_shape=None, seed=20220909),\n",
    "        tf.keras.layers.Dense(number_of_categories, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=(\n",
    "        f\"{number_of_categories}_labels_from_{number_of_features}_features_with_\"\n",
    "        f\"dropout_{dropout}\"\n",
    "    ),\n",
    ")\n",
    "my_tensorflow_model_handler = alb.model.TensorFlowModelHandler()\n",
    "my_tensorflow_model_handler.set_model(my_tensorflow_model)\n",
    "print(\"Tensorflow model handler built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7daeb52-0fe9-4ec1-a1ae-eac04e77b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model handler built\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MyTorchModel(torch.nn.modules.module.Module):\n",
    "    def __init__(self, number_of_features, number_of_categories):\n",
    "        super(MyTorchModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(number_of_features, hidden_units)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(p=dropout)\n",
    "        self.fc2 = torch.nn.Linear(hidden_units, number_of_categories)\n",
    "        self.softmax1 = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "my_torch_model = MyTorchModel(number_of_features, number_of_categories)\n",
    "\n",
    "my_pytorch_model_handler = alb.model.PyTorchModelHandler()\n",
    "my_pytorch_model_handler.set_model(my_torch_model)\n",
    "print(\"PyTorch model handler built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd42e6c1-1a45-483b-9165-fda0468f6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_handler = my_pytorch_model_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e961066-33aa-4ce6-b13d-91927aa6102e",
   "metadata": {},
   "source": [
    "<h2>Active Learning Strategy</h2>\n",
    "Choose an active learning strategy to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7331ecb0-90b8-4b51-b5f1-4c1e1bd855c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_strategy_handler = alb.strategy.RandomStrategyHandler()\n",
    "my_strategy_handler = alb.strategy.LeastConfidenceStrategyHandler()\n",
    "# my_strategy_handler = alb.strategy.LeastMarginStrategyHandler()\n",
    "# my_strategy_handler = alb.strategy.EntropyStrategyHandler()\n",
    "\n",
    "my_strategy_handler.set_dataset_handler(my_dataset_handler)\n",
    "my_strategy_handler.set_model_handler(my_model_handler)\n",
    "my_strategy_handler.set_learning_parameters(\n",
    "    label_of_interest=0,  # We've supplied only one label per feature vector\n",
    "    maximum_iterations=5,\n",
    "    number_to_select_per_iteration=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c97f48-383f-41e9-af12-3a317e9b7c87",
   "metadata": {},
   "source": [
    "<h2>Run the benchmarking tool</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37ed8f7-dab5-448e-b66e-94df79802326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for 4598 examples\n",
      "Training with 20 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 40 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 60 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 80 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 100 examples\n",
      "Predicting for 4598 examples\n"
     ]
    }
   ],
   "source": [
    "# Assume that we start with nothing labeled\n",
    "currently_labeled_examples = set()\n",
    "my_strategy_handler.run(currently_labeled_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa8d17d-f68f-4349-81f5-4c2f10d780a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(log) = 1852\n",
      "log[:3] = [{'utcnow': datetime.datetime(2022, 9, 26, 12, 32, 18, 646768), 'model_step': <ModelStep.ON_PREDICT_BEGIN: 300>, 'logs': None}, {'utcnow': datetime.datetime(2022, 9, 26, 12, 32, 18, 663703), 'model_step': <ModelStep.ON_PREDICT_END: 305>, 'logs': {'outputs': array([[0.29915375, 0.24438834, 0.23698705, 0.21947087],\n",
      "       [0.2740577 , 0.23741184, 0.24258009, 0.2459503 ],\n",
      "       [0.2927576 , 0.23967767, 0.24158762, 0.22597717],\n",
      "       ...,\n",
      "       [0.30666745, 0.22335894, 0.248528  , 0.22144566],\n",
      "       [0.29498193, 0.2238868 , 0.24112754, 0.24000369],\n",
      "       [0.2854142 , 0.25165218, 0.24204808, 0.2208856 ]], dtype=float32)}}, {'utcnow': datetime.datetime(2022, 9, 26, 12, 32, 18, 665561), 'model_step': <ModelStep.ON_TRAIN_BEGIN: 100>, 'logs': None}]\n"
     ]
    }
   ],
   "source": [
    "log = my_strategy_handler.get_log()\n",
    "print(f\"{len(log) = }\")\n",
    "print(f\"{log[:3] = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_bench",
   "language": "python",
   "name": "al_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
