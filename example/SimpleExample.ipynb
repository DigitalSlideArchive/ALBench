{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf11c9d-a1e2-4e9f-9c04-62746cc69738",
   "metadata": {},
   "source": [
    "<h1>al_bench</h1>\n",
    "Example use of the al_bench Active Learning Benchmark Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7634acd-937d-474d-afeb-f3005d981584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install needed packages\n",
    "!pip install h5py numpy tensorflow\n",
    "!pip install -e /tf/notebooks/al_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7e1bd-8315-413d-b3ee-2d38e0777819",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>\n",
    "Fetch a dataset of 4598 feature vectors of length 1280 and their 4598 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5440303-b2c7-49b8-9524-f2159c8e825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 11:00:35.513432: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 4598 feature vectors of length 1280.\n",
      "Read in 4598 labels for the feature vectors.\n"
     ]
    }
   ],
   "source": [
    "import al_bench as alb\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "filename = \"../test/TCGA-A2-A0D0-DX1_xmin68482_ymin39071_MPP-0.2500.h5py\"\n",
    "with h5.File(filename) as ds:\n",
    "    my_feature_vectors = np.array(ds[\"features\"])\n",
    "    print(\n",
    "        f\"Read in {my_feature_vectors.shape[0]} feature vectors of length {my_feature_vectors.shape[1]}.\"\n",
    "    )\n",
    "    my_labels = np.array(ds[\"labels\"])\n",
    "    print(f\"Read in {my_labels.shape[0]} labels for the feature vectors.\")\n",
    "my_label_definitions = [\n",
    "    {\n",
    "        0: {\"description\": \"other\"},\n",
    "        1: {\"description\": \"tumor\"},\n",
    "        2: {\"description\": \"stroma\"},\n",
    "        3: {\"description\": \"infiltrate\"},\n",
    "    }\n",
    "]\n",
    "my_dataset_handler = alb.dataset.GenericDatasetHandler()\n",
    "my_dataset_handler.set_all_feature_vectors(my_feature_vectors)\n",
    "my_dataset_handler.set_all_label_definitions(my_label_definitions)\n",
    "my_dataset_handler.set_all_labels(my_labels)\n",
    "my_dataset_handler.set_validation_indices(list(range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665ae47-e23f-461c-9167-4e4443c4fb81",
   "metadata": {},
   "source": [
    "<h2>Model</h2>\n",
    "Build a model that we will train.  We will build both a TensorFlow model and a PyTorch model, though normally one model is sufficient.  We'll choose one of them for use with the active learning strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3576b1b9-a56a-44c0-ab72-3a4011d927ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "number_of_categories = len(my_label_definitions[0])\n",
    "number_of_features = my_feature_vectors.shape[1]\n",
    "hidden_units = 128\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7350441-53c9-4d31-b5ac-178f984b2698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow model handler built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 11:00:37.129816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1922] Ignoring visible gpu device (device: 1, name: Quadro P400, pci bus id: 0000:a6:00.0, compute capability: 6.1) with core count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-10-13 11:00:37.130356: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-13 11:00:37.726800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22343 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "my_tensorflow_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(number_of_features,)),\n",
    "        tf.keras.layers.Dense(hidden_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout, noise_shape=None, seed=20220909),\n",
    "        tf.keras.layers.Dense(number_of_categories, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=(\n",
    "        f\"{number_of_categories}_labels_from_{number_of_features}_features_with_\"\n",
    "        f\"dropout_{dropout}\"\n",
    "    ),\n",
    ")\n",
    "my_tensorflow_model_handler = alb.model.TensorFlowModelHandler()\n",
    "my_tensorflow_model_handler.set_model(my_tensorflow_model)\n",
    "print(\"Tensorflow model handler built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7daeb52-0fe9-4ec1-a1ae-eac04e77b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model handler built\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MyTorchModel(torch.nn.modules.module.Module):\n",
    "    def __init__(self, number_of_features, number_of_categories):\n",
    "        super(MyTorchModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(number_of_features, hidden_units)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(p=dropout)\n",
    "        self.fc2 = torch.nn.Linear(hidden_units, number_of_categories)\n",
    "        self.softmax1 = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "my_torch_model = MyTorchModel(number_of_features, number_of_categories)\n",
    "\n",
    "my_pytorch_model_handler = alb.model.PyTorchModelHandler()\n",
    "my_pytorch_model_handler.set_model(my_torch_model)\n",
    "print(\"PyTorch model handler built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd42e6c1-1a45-483b-9165-fda0468f6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_handler = my_tensorflow_model_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e961066-33aa-4ce6-b13d-91927aa6102e",
   "metadata": {},
   "source": [
    "<h2>Active Learning Strategy</h2>\n",
    "Choose an active learning strategy to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7331ecb0-90b8-4b51-b5f1-4c1e1bd855c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_strategy_handler = alb.strategy.RandomStrategyHandler()\n",
    "my_strategy_handler = alb.strategy.LeastConfidenceStrategyHandler()\n",
    "# my_strategy_handler = alb.strategy.LeastMarginStrategyHandler()\n",
    "# my_strategy_handler = alb.strategy.EntropyStrategyHandler()\n",
    "\n",
    "my_strategy_handler.set_dataset_handler(my_dataset_handler)\n",
    "my_strategy_handler.set_model_handler(my_model_handler)\n",
    "my_strategy_handler.set_learning_parameters(\n",
    "    label_of_interest=0,  # We've supplied only one label per feature vector\n",
    "    maximum_iterations=5,\n",
    "    number_to_select_per_iteration=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c97f48-383f-41e9-af12-3a317e9b7c87",
   "metadata": {},
   "source": [
    "<h2>Run the benchmarking tool</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37ed8f7-dab5-448e-b66e-94df79802326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for 4598 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 11:00:40.118929: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 20 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 40 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 60 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 80 examples\n",
      "Predicting for 4598 examples\n",
      "Training with 100 examples\n",
      "Predicting for 4598 examples\n"
     ]
    }
   ],
   "source": [
    "# Assume that we start with nothing labeled\n",
    "currently_labeled_examples = set()\n",
    "my_strategy_handler.run(currently_labeled_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc0fc47-a056-4581-bdc2-1be8980566db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(log) = 2590\n",
      "\n",
      "len(some_log) = 5\n",
      "some_log[:10] = [{'utcnow': datetime.datetime(2022, 10, 13, 15, 0, 41, 369890), 'model_step': <ModelStep.ON_TRAIN_END: 105>, 'logs': {'dataset_size': 20, 'loss': 0.25152623653411865, 'accuracy': 0.8999999761581421, 'val_loss': 0.8194094300270081, 'val_accuracy': 0.699999988079071}}, {'utcnow': datetime.datetime(2022, 10, 13, 15, 0, 42, 500745), 'model_step': <ModelStep.ON_TRAIN_END: 105>, 'logs': {'dataset_size': 40, 'loss': 0.03774882107973099, 'accuracy': 1.0, 'val_loss': 0.42392727732658386, 'val_accuracy': 0.8399999737739563}}, {'utcnow': datetime.datetime(2022, 10, 13, 15, 0, 43, 706093), 'model_step': <ModelStep.ON_TRAIN_END: 105>, 'logs': {'dataset_size': 60, 'loss': 0.06042421609163284, 'accuracy': 0.9833333492279053, 'val_loss': 0.4716495871543884, 'val_accuracy': 0.800000011920929}}, {'utcnow': datetime.datetime(2022, 10, 13, 15, 0, 45, 36061), 'model_step': <ModelStep.ON_TRAIN_END: 105>, 'logs': {'dataset_size': 80, 'loss': 0.04587779566645622, 'accuracy': 1.0, 'val_loss': 0.35647186636924744, 'val_accuracy': 0.8299999833106995}}, {'utcnow': datetime.datetime(2022, 10, 13, 15, 0, 46, 205206), 'model_step': <ModelStep.ON_TRAIN_END: 105>, 'logs': {'dataset_size': 100, 'loss': 0.0775241106748581, 'accuracy': 0.9800000190734863, 'val_loss': 0.46908771991729736, 'val_accuracy': 0.8399999737739563}}]\n",
      "\n",
      "By ModelStep, set of supplied keys and number of records:\n",
      "Counter({'<ModelStep.ON_PREDICT_BATCH_BEGIN: 340> utcnow model_step batch logs': 864, '<ModelStep.ON_PREDICT_BATCH_END: 345> utcnow model_step batch logs outputs': 864, '<ModelStep.ON_TEST_BATCH_BEGIN: 240> utcnow model_step batch logs': 200, '<ModelStep.ON_TEST_BATCH_END: 245> utcnow model_step batch logs loss accuracy': 200, '<ModelStep.ON_TRAIN_BATCH_BEGIN: 140> utcnow model_step batch logs': 120, '<ModelStep.ON_TRAIN_BATCH_END: 145> utcnow model_step batch logs loss accuracy': 120, '<ModelStep.ON_TRAIN_EPOCH_BEGIN: 120> utcnow model_step epoch logs': 50, '<ModelStep.ON_TEST_BEGIN: 200> utcnow model_step logs': 50, '<ModelStep.ON_TEST_END: 205> utcnow model_step logs loss accuracy': 50, '<ModelStep.ON_TRAIN_EPOCH_END: 125> utcnow model_step epoch logs loss accuracy val_loss val_accuracy': 50, '<ModelStep.ON_PREDICT_BEGIN: 300> utcnow model_step logs': 6, '<ModelStep.ON_PREDICT_END: 305> utcnow model_step logs': 6, '<ModelStep.ON_TRAIN_BEGIN: 100> utcnow model_step logs': 5, '<ModelStep.ON_TRAIN_END: 105> utcnow model_step logs dataset_size loss accuracy val_loss val_accuracy': 5})\n"
     ]
    }
   ],
   "source": [
    "# Look at the whole log\n",
    "log = my_strategy_handler.get_log()\n",
    "print(f\"{len(log) = }\")\n",
    "\n",
    "# Look at records for one kind of model_step\n",
    "print(\"\")\n",
    "some_log = [\n",
    "    element\n",
    "    for element in log\n",
    "    if element[\"model_step\"] == alb.model.ModelStep.ON_TRAIN_END\n",
    "]\n",
    "print(f\"{len(some_log) = }\")\n",
    "print(f\"{some_log[:10] = }\")\n",
    "\n",
    "# Look at each kind of model_step and what kind of keys and log keys are associated with\n",
    "# it.\n",
    "import collections\n",
    "\n",
    "print(\"\")\n",
    "print(\"By ModelStep, set of supplied keys and number of records:\")\n",
    "print(\n",
    "    collections.Counter(\n",
    "        [\n",
    "            \" \".join(\n",
    "                [repr(entry[\"model_step\"])]\n",
    "                + list(entry.keys())\n",
    "                + (list(entry[\"logs\"].keys()) if entry[\"logs\"] is not None else list())\n",
    "            )\n",
    "            for entry in log\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17176f6a-0155-4e8e-bd08-00f9e89e889b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_bench",
   "language": "python",
   "name": "al_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
